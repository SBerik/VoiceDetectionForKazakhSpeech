{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf2283e0-61e5-4253-bada-a5399206bf5d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Dataset tesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f162605-fbe4-4519-ad35-989e1ab92835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "from utils.load_config import load_config\n",
    "from dataset import VADMelDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23180910-5185-4969-93f7-30601a078064",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-8\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# np.random.seed(42)\n",
    "\n",
    "paths = {'sample':'data/samples/5ed8a1c0f3ea2.flac',\n",
    "        'config_name': '32_n_frames.yml',\n",
    "        'ckpt_folder': 'checkpoints/32_n_frames',\n",
    "        'weight_folder': 'weights/VADNet_13_0.1502_0.9506.pt'}\n",
    "\n",
    "glob_paths = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c54fcf0-82e8-435f-9b64-8d47b0445ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_config('./configs/' + paths['config_name'])\n",
    "params = {key: value for key, value in cfg['data'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "486ab4ec-243c-4a8f-904a-3a3bc24bcb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.65 \n",
    "params['n_workers'] = 6\n",
    "params['train_percent'] = 0.0\n",
    "params['valid_percent'] = 0.0\n",
    "params['test_percent'] = 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caff57fc-422a-4c58-81cf-424fb4631420",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = VADMelDataModule(**params).setup(info = False)\n",
    "full_dataset_dataloader = datamodule.test_set\n",
    "\n",
    "min_n_frames = min([full_dataset_dataloader[i][0].shape[-1] for i in tqdm(range(len(full_dataset_dataloader)))])\n",
    "min_n_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e8c197-5bee-4086-aeda-174b3050c0fd",
   "metadata": {},
   "source": [
    "**Min n_frames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "316f8072-e274-4294-9013-42cb0e41a727",
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = [t.replace('\\\\', '/') for t in glob('F:/ISSAI_KSC2_unpacked/vad_data_augmented/*.flac')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbd739e8-cb7b-4757-bfd4-372b336c5052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min(speeches, n_fft=1048, hop_length=512, n_mels=128):\n",
    "    mel_spec = torchaudio.transforms.MelSpectrogram(n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "    __min = float('inf')\n",
    "    \n",
    "    for t in tqdm(speeches):  \n",
    "        if __min == 32:\n",
    "            break\n",
    "        audio, _ = torchaudio.load(t)\n",
    "        spec = torch.log(mel_spec(audio) + EPS)  \n",
    "        __min = min(__min, spec.shape[-1])  \n",
    "    \n",
    "    return __min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec754c3-af35-4ebf-9682-3f9df75efd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_min(speeches, n_fft=1048, hop_length=512, n_mels=128)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653bdb25-667a-452b-a2e1-2db5c6acaa49",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Testing data shapes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb639f61-1ebb-44df-abfd-772974bc8571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "from omegaconf import OmegaConf\n",
    "from trainer import VAD\n",
    "import yaml\n",
    "import argparse\n",
    "import sys\n",
    "from dataset import VADMelDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349837fd-f779-49d1-bf6f-4768e7c33e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_batch = {\n",
    "    \"spectro\": th.rand(8, 1, 128, 128),  # Размерность входных данных\n",
    "    \"targets\": th.randint(0, 2, (8, 128)).float()  # Бинарные метки размерности (8, 128)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b54ce7e-28f6-45ea-b5c4-34b7e0094c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = VADMelDataModule(**cfg['data'])\n",
    "data_module.setup()\n",
    "train_loader = data_module.train_dataloader()\n",
    "\n",
    "# Size of training set: 555203\n",
    "# Size of validation set: 61689"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f895c1b-ed6e-4a4b-99b7-1cbf94faf253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Извлечение одного батча\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "# Проверка содержимого батча\n",
    "spectro = batch[\"spectro\"]\n",
    "targets = batch[\"targets\"]\n",
    "\n",
    "print(f\"Размер спектрограммы: {spectro.shape}\")\n",
    "print(f\"Размер меток: {targets.shape}\")\n",
    "\n",
    "# Size of training set: 555203\n",
    "# Size of validation set: 61689\n",
    "# Размер спектрограммы: torch.Size([512, 1, 128, 32])\n",
    "# Размер меток: torch.Size([512, 1, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee1d3b6-a2c0-415e-9d92-cfd2cf2a22eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = VADMelDataModule(**cfg['data'])\n",
    "data_module.setup()\n",
    "train_loader = data_module.train_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0351d9f7-0a59-4456-9884-75a063a78be6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Torch training test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eb836a-edc3-4b2e-b857-4f1a9859bd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def p_output_log(epoch, num_epochs, phase, epoch_loss, epoch_metrics, metrics):\n",
    "    if phase == 'train':\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    print(f\"{phase.upper()}, Loss: {epoch_loss:.4f}, \", end=\"\")\n",
    "    for m in metrics.keys():\n",
    "        print(f\"{m}: {epoch_metrics[m]:.4f} \", end=\"\")\n",
    "    print() \n",
    "    if phase == 'valid':\n",
    "        print('-' * 108, '\\n')\n",
    "\n",
    "def __train_model(model, dataloaders, criterion, optimizer, metrics, num_epochs=25, device='cuda'):\n",
    "    model.to(device)\n",
    "    min_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                dataloader = dataloaders['train']\n",
    "            else:\n",
    "                model.eval()\n",
    "                dataloader = dataloaders['valid']\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            [metrics[m].reset() for m in metrics.keys()]\n",
    "            total_samples = len(dataloader.dataset)\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs).transpose(1, 2)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                # Так как значение loss.item() уже усреднено внутри батча, \n",
    "                # чтобы получить общую сумму потерь (а не среднюю) для этого батча, \n",
    "                # нужно домножить её на количество объектов в батче, то есть на inputs.size(0).\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                [metrics[m].update(outputs, labels) for m in metrics.keys()]\n",
    "            \n",
    "            epoch_loss = running_loss / total_samples\n",
    "            epoch_metrics = {m: metrics[m].compute().item() for m in metrics.keys()}\n",
    "            \n",
    "            p_output_log(epoch, num_epochs, phase, epoch_loss, epoch_metrics, metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05534755-1407-453f-b1b5-9dde6fb155ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import torchmetrics\n",
    "# from torch_trainer import train_model\n",
    "import yaml\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import omegaconf as om\n",
    "\n",
    "from models import VADNet \n",
    "from torching_datasets import *\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "def main():\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    cfg = {\n",
    "        'data': {\n",
    "            'data_dir': 'F:/ISSAI_KSC2_unpacked/temp_vad',\n",
    "            'batch_size': 512,\n",
    "            'valid_percent': 0.9,\n",
    "            'n_frames': 32,\n",
    "            'nfft': 1048,\n",
    "            'hop_length': 512,\n",
    "            'n_mels': 128,\n",
    "            'sr': 16000,\n",
    "            'norm': False,\n",
    "            'n_workers': 2,\n",
    "            'pin_memory': True,\n",
    "            'seed': 42\n",
    "        },\n",
    "        'model': {\n",
    "            'n_feat': 128,\n",
    "            'cnn_channels': 32,\n",
    "            'embed_dim': 256,\n",
    "            'dff': 512,\n",
    "            'num_heads': 16\n",
    "        },\n",
    "        'training': {\n",
    "            'optim': 'Adam',\n",
    "            'lr': 0.01,\n",
    "            'weight_decay': 1e-05\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Load data \n",
    "    datamodule = VADMelDataModule(**cfg['data'])\n",
    "    datamodule.setup()\n",
    "    dataloaders = {'train': datamodule.train_dataloader(), 'valid': datamodule.val_dataloader()}\n",
    "\n",
    "    model = VADNet(**cfg['model'])\n",
    "    \n",
    "    # Meta-data\n",
    "    print(f\"Trainable parametrs: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
    "\n",
    "    # Optimizer\n",
    "    optim_type = cfg['training'][\"optim\"]\n",
    "    assert  optim_type in ['Adam', 'SGD']\n",
    "    if optim_type == 'Adam':\n",
    "        optimizer = th.optim.Adam(model.parameters(), lr=cfg['training'][\"lr\"], weight_decay=cfg['training'][\"weight_decay\"])\n",
    "    else: \n",
    "        optimizer = th.optim.SGD(model.parameters(), lr=cfg['training'][\"lr\"], weight_decay=cfg['training'][\"weight_decay\"])\n",
    "\n",
    "    # Metrics: accuracy. Changes macro changed to micro\n",
    "    metrics = {m: getattr(torchmetrics, m)(task='binary', average='micro').to(device) for m in ['Accuracy']}\n",
    "\n",
    "    # Start training. Hardcode: num_epochs = 100\n",
    "    trained_model = __train_model(model, dataloaders, nn.BCEWithLogitsLoss(), optimizer, metrics, num_epochs=100, \n",
    "                                device=device)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35035fd3-d1e9-4e08-a218-27e33355d554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# # Пример входного тензора (input size)\n",
    "# input_tensor = torch.randn(512, 32)  # Тензор размера [512, 32]\n",
    "# # Пример целевого тензора (target size)\n",
    "# target_tensor = torch.randn(512, 1, 32)  # Тензор размера [512, 1, 32]\n",
    "# # Печать форм тензоров\n",
    "# print(\"Input tensor size:\", input_tensor.size())\n",
    "# print(\"Target tensor size:\", target_tensor.size())\n",
    "\n",
    "# a_target_tensor = target_tensor.squeeze(1) # squeeze -1 transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7dbe77-b43d-409f-85c4-692cd20b8b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.00001\n",
    "b = 1e-05\n",
    "print(a == b )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b68540-f469-46f2-9a31-e26dfa006ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2a16f0-759b-43b2-b453-9d3a1aa728c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
